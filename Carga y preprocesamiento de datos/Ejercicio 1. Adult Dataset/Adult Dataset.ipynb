{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 - *Adult* [dataset](https://archive.ics.uci.edu/ml/datasets/Adult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga y Preprocesamiento de los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import os # Para obtener el directorio activo\n",
    "import requests # Para descargar ficheros\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una carpeta para que contenga a nuestro dataset\n",
    "!mkdir adult_dataset\n",
    "# Movemos el directorio activo a esa localización\n",
    "os.chdir(\"adult_dataset\")\n",
    "\n",
    "url_data = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "url_names = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names'\n",
    "\n",
    "response_data = requests.get(url_data)\n",
    "response_names = requests.get(url_names)\n",
    "\n",
    "# Guardar los archivos descargados\n",
    "with open('adult.data', 'wb') as f:\n",
    "    f.write(response_data.content)\n",
    "\n",
    "with open('adult.names', 'wb') as f:\n",
    "    f.write(response_names.content)\n",
    "\n",
    "# Leemos datos\n",
    "with open(os.path.join(os.getcwd(),'adult.data'),'r') as f:\n",
    "    data = f.read().splitlines() # Dividimos el texto por saltos de línea\n",
    "    data = [elem.split(',') for elem in data] # Dividimos cada línea por las comas y removemos líneas vacías\n",
    "\n",
    "# Leemos metadata\n",
    "with open(os.path.join(os.getcwd(),'adult.names'),'r') as f:\n",
    "    metadata = f.read().splitlines()\n",
    "\n",
    "# Regex\n",
    "## Buscamos palabras que empiecen por letras mayús. o minús. de duración variable y que tengan dos puntos\n",
    "regex_fn = lambda text: re.findall('^[a-zA-Z-]+:{1}', text)  \n",
    "## Buscamos palabras con letras mayús. o minús. de duración variable\n",
    "reg_text_fn = lambda text : re.findall('[a-zA-Z- ]+', text)  \n",
    "\n",
    "# Aplicamos la expresión regular en forma de lambda a al metadata\n",
    "# Téngase en cuenta que el método findall devuelve una lista vacía si ninguna expresión coincide con el patrón introducido\n",
    "\n",
    "metadata_list = [regex_fn(elem)[0] for elem in metadata if regex_fn(elem)]\n",
    "col_names = [reg_text_fn(elem)[0] for elem in metadata_list if reg_text_fn(elem)] + ['label']\n",
    "\n",
    "# Construimos el objeto pd.DataFrame\n",
    "df_ADULT = pd.DataFrame(data=data, columns=col_names)\n",
    "df_ADULT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos el análisis de los datos buscando su información general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ADULT.copy() # Copiamos el dataframe para no modificar el original y trabajar con una variable de nombre corto.\n",
    "df.info() # Como se puede apreciar, todas las columnas son de \"Dtype: object\", lo que quiere decir que probablemente sean strings, cosa que no tiene\n",
    "# sentido, por ejemplo, para la edad. De hecho, si vamos a la fuente, observaremos lo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción de las variables:\n",
    "- age: continuous.\n",
    "- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- fnlwgt: continuous.\n",
    "- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- education-num: continuous.\n",
    "- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- sex: Female, Male.\n",
    "- capital-gain: continuous.\n",
    "- capital-loss: continuous.\n",
    "- hours-per-week: continuous.\n",
    "- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "Por lo pronto, vamos a ver el aspecto de los primeros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # Al menos 6 de las columnas deben ser numéricas tal y como está indicado en adult.names (continuous)\n",
    "# Estas variables son: age, fnlwgt, education-num, capital-gain, capital-loss y hours-per-week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordatorio: una forma de hacerlo directamente con **todas** las variables que se pueda es la siguiente:\n",
    "```python\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "\n",
    "df.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación del tipo de las variables a numérico:\n",
    "\n",
    "df[\"age\"] = df[\"age\"].astype(int)\n",
    "df[\"fnlwgt\"] = df[\"fnlwgt\"].astype(int)\n",
    "df[\"education-num\"] = df[\"education-num\"].astype(int)\n",
    "df[\"capital-gain\"] = df[\"capital-gain\"].astype(int)\n",
    "df[\"capital-loss\"] = df[\"capital-loss\"].astype(int)\n",
    "df[\"hours-per-week\"] = df[\"hours-per-week\"].astype(int)\n",
    "\n",
    "# Finalmente, comprobamos que las variables son números ahora:\n",
    "df.info()\n",
    "\n",
    "# Obtenemos un error porque uno de los valores, además de ser un string, es un string vacío, por lo que no puede ser transformado a int."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos entonces a estudiar los valores nulos de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"].unique() # Se puede ver que uno de los valores es un vacío, por lo que no vamos a poder convertir los datos de string a número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"].isnull().value_counts() # Vemos que no hay valores nulos, sino un string vacío, asi que vamos a corregir esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"] #Parece que es el último dato el que falla, vamos a ver las últimas filas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() # En efecto, en la base de datos hay una fila extra vacía que provoca fallos y no aporta información, así que vamos a borrarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para borrar la última fila, podemos hacer lo siguiente:\n",
    "df.index[-1] # Nos da el índice de la fila del final, comprobamos que es la 32561\n",
    "df = df.drop(df.index[32561]) # Borramos la fila del final, la 32561\n",
    "df.tail()\n",
    "\n",
    "# Este código solo va a funcionar una vez pues la fila 32561 ya no existe, pero si indicásemos la fila del final con un -1, se borraría la última fila\n",
    "# constantemente al ejecutar este comando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una forma de que no pase lo anterior sería la siguiente:\n",
    "df = df_ADULT.copy() # Explicitamos esta línea aquí para generar el df de nuevo.\n",
    "df = df.drop(df.index[-1])  # Borramos la última fila.\n",
    "df.tail() # Ahora siempre se verá que la última fila es la número 32560 da igual cuantas veces se ejecute el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación del tipo de las variables a numérico:\n",
    "\n",
    "df[\"age\"] = df[\"age\"].astype(int)\n",
    "df[\"fnlwgt\"] = df[\"fnlwgt\"].astype(int)\n",
    "df[\"education-num\"] = df[\"education-num\"].astype(int)\n",
    "df[\"capital-gain\"] = df[\"capital-gain\"].astype(int)\n",
    "df[\"capital-loss\"] = df[\"capital-loss\"].astype(int)\n",
    "df[\"hours-per-week\"] = df[\"hours-per-week\"].astype(int)\n",
    "\n",
    "# Finalmente, comprobamos que las variables son números ahora:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aquí, hemos eliminado todos los valores nulos, ahora hay que comprobar si los valores no-nulos son valores válidos o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De forma un poco rudimentaria, pero útil a modo de práctica, podemos emplear el comando .unique() para ver los valores únicos de cada columna\n",
    "\n",
    "#print(df[\"age\"].unique()) # Todo correcto, ponemos un # para que la línea no se ejecute \n",
    "\n",
    "#####print(df[\"workclass\"].unique()) # Problemas, hay una categoría de datos que es \"?\"\n",
    "\n",
    "#print(df[\"fnlwgt\"].unique()) # No se pueden ver todos los datos, hace falta otro método, como un groupby. ### Comprobado que está bien.\n",
    "\n",
    "#print(df[\"education\"].unique()) # Todo correcto\n",
    "\n",
    "#print(df[\"education-num\"].unique()) # Todo correcto\n",
    "\n",
    "#print(df[\"marital-status\"].unique()) # Todo correcto\n",
    "\n",
    "#####print(df[\"occupation\"].unique()) # Hay una categoría \"?\"\n",
    "\n",
    "#print(df[\"relationship\"].unique()) # Todo correcto\n",
    "\n",
    "#print(df[\"race\"].unique()) # Todo correcto\n",
    "\n",
    "#print(df[\"sex\"].unique()) # Todo correcto\n",
    "\n",
    "#print(df[\"capital-gain\"].unique()) # Todo correcto\n",
    "\n",
    "#print(df[\"capital-loss\"].unique()) # Todo correcto\n",
    "\n",
    "#print(df[\"hours-per-week\"].unique()) # Todo correcto, aunque hay gente que trabaja más de 90h a la semana, pobrecitos\n",
    "\n",
    "#####print(df[\"native-country\"].unique()) # Hay una categoría \"?\"\n",
    "\n",
    "#print(df[\"label\"].unique()) # Todo correcto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una forma más rápida y directa es con el siguiente comando:\n",
    "for col in df.columns: # Para cada columna del dataframe:\n",
    "    print(df[col].unique()) # Imprimimos los valores/categorías únicas de cada columna\n",
    "    print(\"\\n\") # y un espacio de línea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma rápida de agrupar las variables es con el código que viene a continuación:  \n",
    "\n",
    "```python\n",
    "# Sacamos los nombres de las columnas numéricas y categóricas\n",
    "def tipo_de_columnas_ordenadas (df):\n",
    "    cat = []\n",
    "    num = []\n",
    "        \n",
    "    for col in df.columns:\n",
    "        if(df[col].dtype == \"object\"):\n",
    "            cat.append(col)\n",
    "        else:\n",
    "            num.append(col)\n",
    "\n",
    "    return cat , num\n",
    "\n",
    "cat , num = tipo_de_columnas_ordenadas(df)\n",
    "print(\"Las columnas categóricas son: \", cat)\n",
    "print(\"Las columnas numéricas son: \", num)\n",
    "\n",
    "# Es una buena forma de agrupar las variables según su tipo, especialmente cuando tenemos un número elevado de columnas, aunque requiere de una buena\n",
    "# limpieza previa de los datos.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a estudiar los casos específicos de \"workclass\", \"fnlwgt\", \"occupation\" y \"native-country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"workclass\"].value_counts() # Hay 1836 valores que no tienen una \"?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sort_values(by = \"fnlwgt\")) # En la columna fnlwgt no hay valores extraños como \"?\" ni cerca del mínimo ni del máximo, por lo que esta variable está bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"occupation\"].value_counts() # Hay 1843 valores que no tienen valores de profesión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"native-country\"].value_counts() # Hay 583 personas que no tienen país de origen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a eliminar entonces los datos indeterminados y sustituirlos por valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazamos ' ?' (si, con espacio) por nulo\n",
    "df = df.replace(' ?',np.NaN)\n",
    "\n",
    "# Vemos qué columnas tienen datos faltantes\n",
    "missing_cols = list(df.isnull().sum(axis=0)[df.isnull().sum(axis=0)>0].index)\n",
    "\n",
    "# Filtramos las filas donde hay algún dato nulo, y las columnas donde están\n",
    "df.loc[df.isnull().sum(axis=1)>0, missing_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos valores nulos en Workclass, Occupation y Native-Country. ¿Qué podemos hacer con ellos? Al ser variables atributos (no numéricas, sino palabras, categóricas) la mejor opción es asignarles la moda a esos valores, que son \"Private\", \"Prof-Specialty\" y \"USA\" respectivamente.\n",
    "\n",
    "```python\n",
    "def replace_missing_data(df):\n",
    "    # Vemos qué columnas tienen valores nulos\n",
    "    mis_cols = list(df.isnull().sum(axis=0)[df.isnull().sum(axis=0)>0].index)\n",
    "    # Iteramos sobre ellas\n",
    "    for col in mis_cols:\n",
    "        # Si la variable es discreta,...\n",
    "        if df[col].dtype in ['object']:\n",
    "            mode_col = df[col].mode().values[0]\n",
    "            df[col] = df[col].fillna(mode_col)\n",
    "        # Si son números enteros\n",
    "        elif df[col].dtype in ['int']:\n",
    "            df[col] = df[col].fillna(df['col'].median())\n",
    "        # Si son números reales\n",
    "        elif df[col].dtype in ['float']:\n",
    "            df[col] = df[col].fillna(df['col'].mean())\n",
    "    # Devolvemos el DataFrame\n",
    "    return df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_data(df):\n",
    "    # Vemos qué columnas tienen valores nulos\n",
    "    mis_cols = list(df.isnull().sum(axis=0)[df.isnull().sum(axis=0)>0].index)\n",
    "    # Iteramos sobre ellas\n",
    "    for col in mis_cols:\n",
    "        # Si la variable es discreta,...\n",
    "        if df[col].dtype in ['object']:\n",
    "            mode_col = df[col].mode().values[0]\n",
    "            df[col] = df[col].fillna(mode_col)\n",
    "        # Si son números enteros\n",
    "        elif df[col].dtype in ['int']:\n",
    "            df[col] = df[col].fillna(df['col'].median())\n",
    "        # Si son números reales\n",
    "        elif df[col].dtype in ['float']:\n",
    "            df[col] = df[col].fillna(df['col'].mean())\n",
    "    # Devolvemos el DataFrame\n",
    "    return df\n",
    "\n",
    "replace_missing_data(df)\n",
    "print(df.info()) # Hemos solucionado todos los errores nulos\n",
    "df[[\"workclass\", \"occupation\", \"native-country\"]][60:63] # Antes había problemas en workclass, occupation y native-country en la linea 61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos corregido nuestra base de datos. Hemos eliminado celdas vacías y hemos sustituido los valores nulos por la moda de sus respectivas columnas al tratarse de variables atributo (palabras). Nuestra base de datos ya está lista para ser estudiada y analizada por los expertos 😎👌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordatorio: Código para discretizar variables:\n",
    "\n",
    "```python\n",
    "  # Tomamos el mínimo y máximo de los datos\n",
    "  min_col, max_col = df['engine-size'].min(), df['engine-size'].max()\n",
    "  # Decidimos en cuántas cajas vamos a estratificar los datos\n",
    "  num_boxes = 8\n",
    "  # Creamos los valores que segmentarán las cajas\n",
    "  bins = np.linspace(min_col, max_col, num_boxes+1)\n",
    "  # Creamos la columna discretizada\n",
    "  df['engine-size-disc'] = np.digitize(df['engine-size'], bins)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis estadístico de los datos (Explayarse todo lo que uno quiera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intervalo de edad\n",
    "intervalo_edad = df[\"age\"].max()-df[\"age\"].min()\n",
    "\n",
    "#Histograma con la edad\n",
    "df[\"age\"].hist(bins = intervalo_edad, color = \"green\", edgecolor = \"grey\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
