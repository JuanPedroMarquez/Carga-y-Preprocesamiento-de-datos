{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 - Solar flare [dataset](https://archive.ics.uci.edu/ml/datasets/Solar+Flare)\n",
    "\n",
    "En este conjunto de datos, tendremos dos ficheros relativos a `data`, cuya primera fila serán las especificaciones temporales, por lo que deberemos quitarla, y además en los registros de datos las variables no vienen delimitadas por `','`, si no por espacios en blanco:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La manera de Andrés (no me funciona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movemos el directorio activo a una nueva localización para este dataset\n",
    "## Retrocedemos dos niveles\n",
    "%cd ..\n",
    "%cd ..\n",
    "## Creamos carpeta\n",
    "!mkdir /content/solar_flare_dataset\n",
    "## Movemos directorio activo\n",
    "%cd /content/solar_flare_dataset\n",
    "# Descargamos los ficheros que contienen los datos a nuestro directorio activo\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.data1\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.data2\n",
    "# Descargamos la metadata asociada al conjunto de datos\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.names\n",
    "# Leemos datos\n",
    "## Leemos primer fichero de datos\n",
    "with open(os.path.join(os.getcwd(),'flare.data1'),'r') as f:\n",
    "    data1 = f.read().splitlines() # Dividimos el texto por saltos de línea\n",
    "    data1 = [elem.split(' ') for elem in data1 if elem!=''] # Dividimos cada línea por las comas y removemos líneas vacías\n",
    "    data1 = data1[1:] # Quitamos la línea de metadata temporal\n",
    "## Leemos segundo fichero de datos\n",
    "with open(os.path.join(os.getcwd(),'flare.data2'),'r') as f:\n",
    "    data2 = f.read().splitlines() # Dividimos el texto por saltos de línea\n",
    "    data2 = [elem.split(' ') for elem in data2 if elem!=''] # Dividimos cada línea por las comas y removemos líneas vacías\n",
    "    data2 = data2[1:] # Quitamos la línea de metadata temporal\n",
    "## Combinamos ambas listas\n",
    "data = data1+data2\n",
    "# Leemos metadata\n",
    "with open(os.path.join(os.getcwd(),'flare.names'),'r') as f:\n",
    "    metadata = f.read().splitlines()\n",
    "## Regex\n",
    "regex_fn = lambda text: re.findall('^\\s+[0-9]+\\.{1}\\s{1}[a-zA-Z- ]+', text)\n",
    "reg_text_fn = lambda text : re.findall('[a-zA-Z-]+', text)\n",
    "metadata_list = [regex_fn(elem)[0].strip() for elem in metadata if regex_fn(elem)]\n",
    "col_names = [reg_text_fn(elem)[0] for elem in metadata_list if reg_text_fn(elem)]\n",
    "# Construimos el objeto pd.DataFrame\n",
    "df = pd.DataFrame(data=data, columns=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La manera de Demetrio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.data1 <br>\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.data1'\n",
    "url2 = 'https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.data2'\n",
    "url3 = 'https://archive.ics.uci.edu/ml/machine-learning-databases/solar-flare/flare.names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos qué tenemos dentro de cada variable\n",
    "# data1\n",
    "import requests\n",
    "response = requests.get(url1)\n",
    "data1 = response.text\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve que los datos están separados por espacios en vez de por comas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2\n",
    "response = requests.get(url2)\n",
    "data2 = response.text\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos un dataframe con los datos de data1 y data2 \n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "#Leemos los datos como un csv de string separado por espacios\n",
    "data1df = pd.read_csv(io.StringIO(data1), sep=' ')\n",
    "data2df = pd.read_csv(io.StringIO(data2), sep=' ')\n",
    "\n",
    "#vemos que tenemos en data1\n",
    "data1df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos que tenemos en data2\n",
    "data2df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podemos ver el mismo problema en el nombre de las columnas, ya que usaron un texto como nombre de columna\n",
    "#vamos a quitar ese texto de los archivos\n",
    "#recuerden que el texto lo podemos ver arriba cuando hicimos el print es *******DATA1;\t1969\tFLARE\tDATA\tUnnamed: 4\t(02/13/69\tto\t03/27/69)\t*******\n",
    "#y \t*******\tDATA2;\t1978\tFLARE\tDATA\t(08/19/78\tto\t12/23/78)\t*****\n",
    "\n",
    "#vamos a quitar el texto de las columnas creando nuevos dataframes a partir del texto que queremos quitar\n",
    "data1 \n",
    "#al hacer el print vemos como despues del texto que queremos quitar empiezan los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mediante expresiones regulares vamos a quitar el texto que no queremos\n",
    "import re\n",
    "\n",
    "#esto significa que vamos a quitar todo lo que este antes de DATA1; y todo lo que este despues de DATA1; y antes de un salto de linea, y lo vamos a \n",
    "#sustituir por \"\" en data1 (y lo mismo para data2)\n",
    "data1 = re.sub(r'.*DATA1;.*\\n', '', data1) \n",
    "data2 = re.sub(r'.*DATA2;.*\\n', '', data2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#podemos crear un df ahora con los datos limpios, separados por espacios\n",
    "\n",
    "#Volvemos a hacer lo mismo de antes, pero ahora con los datos 1 y 2 transformados con la operación anterior.\n",
    "data1df = pd.read_csv(io.StringIO(data1), sep=' ', header=None)   #header=none para que no tome la primera fila como nombre de columna\n",
    "data2df = pd.read_csv(io.StringIO(data2), sep=' ' , header=None)  #.io para que lo tome como un archivo de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos limpiado los datos, vamos a trabajar con el archivo de nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url3)\n",
    "data3 = response.text\n",
    "print(data3) #vemos que las columnas estan en el punto 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo accedemos a los nombres de las columnas, que están en el apartado 7 de data3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraemos la info del punto 7. \"Attribute Information\" , vemos que tenemos el 7 con un punto, eso es bueno para localizar\n",
    "#Vamos a quedarnos con lo que exista despues del punto 7 y antes del punto 8\n",
    "data3 = re.search(r'7\\..*8\\.', data3, re.DOTALL).group(0) #re.DOTALL para que tome en cuenta los saltos de linea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data3) #Vemos la información que ha extraído de data 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora queremos acceder a cada uno de los puntos para convertirlos en los encabezados del df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos un patron para extraer los nombres de las columnas\n",
    "\n",
    "#\\d+ para que tome cualquier numero de digitos\n",
    "#\\s+ para que tome cualquier espacio en blanco\n",
    "#[^\\(\\n]+ para que tome cualquier caracter que no sea un parentesis o un salto de linea\n",
    "\n",
    "pattern = re.compile(r'\\d+\\.\\s+([^\\(\\n]+)') \n",
    "\n",
    "# Encontramos todas las coincidencias\n",
    "columns = pattern.findall(data3) #findall \n",
    "\n",
    "# Mostramos los nombres de las columnas con un bucle\n",
    "for col in columns:\n",
    "    print(col.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora eliminamos la palabra 'Number' de las últimas 3 filas y Attribute Information: de la primera fila de nuestra nueva variable columns\n",
    "columns = [re.sub(r'Number', '', col) for col in columns] #re.sub para reemplazar 'Number' por nada en \"col\"\n",
    "columns = [re.sub(r'Attribute Information:', '', col) for col in columns] #re.sub para reemplazar 'Attribute Information:' por nada en \"col\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns #vemos que ya no tenemos 'Number' ni 'Attribute Information:', ahora podemos limpiar todo de caracteres especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vamos a limpiar los nombres de las columnas eliminando los espacios en blanco y caracteres especiales\n",
    "columns = [re.sub(r'[^\\w]', '', col) for col in columns] #re.sub para reemplazar cualquier caracter que no sea una letra o un numero por nada en (cada) col\n",
    "columns = [col.lower() for col in columns] #pasamos todo a minusculas\n",
    "\n",
    "columns #vemos que ya tenemos los nombres de las columnas limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos el primer elemento de la lista ya que esta vacio\n",
    "if columns and columns[0] == '':\n",
    "    columns.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto ya hemos obtenido los nombres de todas las columnas de data1 y data2, por lo que vamos a unirlos y a indicar sus columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data1df, data2df], axis=0) #unimos ambas bases de datos. axis=0 para concatenar por filas\n",
    "df.columns = columns #asignamos los nombres de las columnas\n",
    "df.head() #vemos que ya tenemos nuestro df limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis estadístico de los datos (Explayarse todo lo que uno quiera)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
