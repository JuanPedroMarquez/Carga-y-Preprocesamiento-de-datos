{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 - Beijing Multi-Site [Air Quality Data](https://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este conjunto de datos no tendremos que hacer un esfuerzo muy grande en lo relativo a estudiar la *metadata*, pero exploraremos una serie de comandos de Linux que nos será muy útil conocer.\n",
    "\n",
    "La particularidad de este ejercicio está en que juntamos varios Excel en uno solo, obteniendo una base de datos gigantesca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga y Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import os # Para obtener el directorio activo\n",
    "import requests # Para descargar ficheros\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La manera de Andrés (no me funcionó, pero la dejo a modo de otra posibilidad disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movemos el directorio activo a una nueva localización para este dataset\n",
    "## Retrocedemos un nivel\n",
    "%cd ..\n",
    "## Creamos carpeta\n",
    "!mkdir /content/air_quality_dataset\n",
    "## Movemos directorio activo\n",
    "%cd /content/air_quality_dataset\n",
    "# Descargamos fichero comprimido\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00501/PRSA2017_Data_20130301-20170228.zip\n",
    "# Descargamos el fichero que contiene los datos a nuestro directorio activo\n",
    "!unzip PRSA2017_Data_20130301-20170228.zip\n",
    "# Nos movemos a la carpeta que contenía el zip\n",
    "%cd PRSA_Data_20130301-20170228"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La manera de Demetrio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducimos los datos: https://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo primero que vemos aquí, es que la url ya no conduce a los datos, con lo cual dentro de esa página, en su buscador, escribimos beijing y \n",
    "# accedemos a los datos.\n",
    "\n",
    "nueva_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00501/PRSA2017_Data_20130301-20170228.zip'\n",
    "\n",
    "# Tenemos una extension .zip, lo que quiere decir que es un archivo comprimido, por lo que necesitamos descomprimirlo.\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# Vamos a crear una carpeta donde guardaremos los datos\n",
    "import os\n",
    "\n",
    "# Creamos la carpeta \"beijing\" y nos movemos allí para establecerlo como nuestro directorio activo, además, si ya existe, no generará más.\n",
    "os.makedirs('./beijing', exist_ok=True)\n",
    "\n",
    "# Descargamos el archivo (en beijing)\n",
    "r = requests.get(nueva_url)\n",
    "\n",
    "# Creamos un objeto zipfile (en beijing)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "# Extraemos los archivos (adivinaste, en beijing)\n",
    "z.extractall('./beijing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el dataframe con los datos. Como se puede ver en los csv, todos los datos tienen las mismas columnas, así que se pueden concatenar sin problema para formar una única masa de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creamos un dataframe vacío\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Iteramos sobre los archivos de la carpeta beijing y los leemos con pandas(recuerden que al descomprimir, se creó \n",
    "# Una carpeta nueva: C:\\Users\\demst\\OneDrive\\Escritorio\\preprocesamiento\\beijing\\PRSA_Data_20130301-20170228)\n",
    "\n",
    "for file in os.listdir('./beijing/PRSA_Data_20130301-20170228'): # Por cada archivo en nuestra carpeta \"beijing/PRSA_Data_20130301-20170228\" del notebook:\n",
    "    if file.endswith('.csv'):                                    # Si el archivo termina en .csv:\n",
    "        df = pd.concat([df, pd.read_csv('./beijing/PRSA_Data_20130301-20170228/' + file)])  #leemos el archivo y lo concatenamos a nuestro dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>wd</th>\n",
       "      <th>WSPM</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>-18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.2</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>1024.5</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1025.2</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>35060</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1013.5</td>\n",
       "      <td>-16.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>35061</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>1013.6</td>\n",
       "      <td>-15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>35062</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1014.2</td>\n",
       "      <td>-13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>35063</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1014.4</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>35064</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1014.1</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420768 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          No  year  month  day  hour  PM2.5  PM10   SO2   NO2     CO    O3  \\\n",
       "0          1  2013      3    1     0    4.0   4.0   4.0   7.0  300.0  77.0   \n",
       "1          2  2013      3    1     1    8.0   8.0   4.0   7.0  300.0  77.0   \n",
       "2          3  2013      3    1     2    7.0   7.0   5.0  10.0  300.0  73.0   \n",
       "3          4  2013      3    1     3    6.0   6.0  11.0  11.0  300.0  72.0   \n",
       "4          5  2013      3    1     4    3.0   3.0  12.0  12.0  300.0  72.0   \n",
       "...      ...   ...    ...  ...   ...    ...   ...   ...   ...    ...   ...   \n",
       "35059  35060  2017      2   28    19   11.0  32.0   3.0  24.0  400.0  72.0   \n",
       "35060  35061  2017      2   28    20   13.0  32.0   3.0  41.0  500.0  50.0   \n",
       "35061  35062  2017      2   28    21   14.0  28.0   4.0  38.0  500.0  54.0   \n",
       "35062  35063  2017      2   28    22   12.0  23.0   4.0  30.0  400.0  59.0   \n",
       "35063  35064  2017      2   28    23   13.0  19.0   4.0  38.0  600.0  49.0   \n",
       "\n",
       "       TEMP    PRES  DEWP  RAIN   wd  WSPM        station  \n",
       "0      -0.7  1023.0 -18.8   0.0  NNW   4.4   Aotizhongxin  \n",
       "1      -1.1  1023.2 -18.2   0.0    N   4.7   Aotizhongxin  \n",
       "2      -1.1  1023.5 -18.2   0.0  NNW   5.6   Aotizhongxin  \n",
       "3      -1.4  1024.5 -19.4   0.0   NW   3.1   Aotizhongxin  \n",
       "4      -2.0  1025.2 -19.5   0.0    N   2.0   Aotizhongxin  \n",
       "...     ...     ...   ...   ...  ...   ...            ...  \n",
       "35059  12.5  1013.5 -16.2   0.0   NW   2.4  Wanshouxigong  \n",
       "35060  11.6  1013.6 -15.1   0.0  WNW   0.9  Wanshouxigong  \n",
       "35061  10.8  1014.2 -13.3   0.0   NW   1.1  Wanshouxigong  \n",
       "35062  10.5  1014.4 -12.9   0.0  NNW   1.2  Wanshouxigong  \n",
       "35063   8.6  1014.1 -15.9   0.0  NNE   1.3  Wanshouxigong  \n",
       "\n",
       "[420768 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # Echamos un vistazo a los primeros y últimos datos, así como a sus dimensiones (420768 filas por 18 columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 420768 entries, 0 to 35063\n",
      "Data columns (total 18 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   No       420768 non-null  int64  \n",
      " 1   year     420768 non-null  int64  \n",
      " 2   month    420768 non-null  int64  \n",
      " 3   day      420768 non-null  int64  \n",
      " 4   hour     420768 non-null  int64  \n",
      " 5   PM2.5    412029 non-null  float64\n",
      " 6   PM10     414319 non-null  float64\n",
      " 7   SO2      411747 non-null  float64\n",
      " 8   NO2      408652 non-null  float64\n",
      " 9   CO       400067 non-null  float64\n",
      " 10  O3       407491 non-null  float64\n",
      " 11  TEMP     420370 non-null  float64\n",
      " 12  PRES     420375 non-null  float64\n",
      " 13  DEWP     420365 non-null  float64\n",
      " 14  RAIN     420378 non-null  float64\n",
      " 15  wd       418946 non-null  object \n",
      " 16  WSPM     420450 non-null  float64\n",
      " 17  station  420768 non-null  object \n",
      "dtypes: float64(11), int64(5), object(2)\n",
      "memory usage: 61.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() # Observamos los datos nulos en cada variable/columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Ya tenemos nuestro df, ahora vamos a comprobar los valores repetidos y los valores nulos\n",
    "print(df.duplicated().sum()) # df.duplicated indica un booleano si hay valores duplicados, y sum() los agrega. Como se puede ver, no hay valores repes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sabemos que no hay valores repetidos, pero, ¿qué hay de los valores nulos? En la tabla anterior (df.info()) hemos visto que sí hay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No             0\n",
      "year           0\n",
      "month          0\n",
      "day            0\n",
      "hour           0\n",
      "PM2.5       8739\n",
      "PM10        6449\n",
      "SO2         9021\n",
      "NO2        12116\n",
      "CO         20701\n",
      "O3         13277\n",
      "TEMP         398\n",
      "PRES         393\n",
      "DEWP         403\n",
      "RAIN         390\n",
      "wd          1822\n",
      "WSPM         318\n",
      "station        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#nulos por agregación\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No         0.000000\n",
      "year       0.000000\n",
      "month      0.000000\n",
      "day        0.000000\n",
      "hour       0.000000\n",
      "PM2.5      2.076916\n",
      "PM10       1.532674\n",
      "SO2        2.143937\n",
      "NO2        2.879497\n",
      "CO         4.919813\n",
      "O3         3.155421\n",
      "TEMP       0.094589\n",
      "PRES       0.093401\n",
      "DEWP       0.095777\n",
      "RAIN       0.092688\n",
      "wd         0.433018\n",
      "WSPM       0.075576\n",
      "station    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#nulos por % \n",
    "print(df.isnull().sum()/len(df)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, parece que variables como NO2, CO u O3, entre otros, tienen gran cantidad de datos faltantes, pero en términos relativos no suponen ni el 5% del total. Esto también es importante tenerlo en cuenta para saber si seremos capaces o si sería responsable tomar la decisión de sustituir los datos faltantes a raíz de los existentes (podemos rellenar el 2% con el otro 98%, pero no podemos rellenar un 85% con un 15%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No           int64\n",
      "year         int64\n",
      "month        int64\n",
      "day          int64\n",
      "hour         int64\n",
      "PM2.5      float64\n",
      "PM10       float64\n",
      "SO2        float64\n",
      "NO2        float64\n",
      "CO         float64\n",
      "O3         float64\n",
      "TEMP       float64\n",
      "PRES       float64\n",
      "DEWP       float64\n",
      "RAIN       float64\n",
      "wd          object\n",
      "WSPM       float64\n",
      "station     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#vemos de que tipo son nuestros datos\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparamos los valores nulos usando la super-mega-función de Andrés para reparar float, objects e ints, ya que representan \n",
    "# muy poco % de los datos y no afectarán el modelo. Si el % fuera mayor (por ejemplo, un 20%) podriamos usar el algoritmo KNN\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    for col in df.columns:  # Para cada columna en df:\n",
    "        if df[col].dtype == 'float64':  # Si el tipo de dato es float64:\n",
    "            df[col] = df[col].fillna(df[col].mean()) # Sustituimos los valores nulos con la MEDIA de la columna\n",
    "        elif df[col].dtype == 'object': # Si el tipo de dato es object (señal de que suele ser string):\n",
    "            df[col] = df[col].fillna(df[col].mode()[0]) # Sustituimos los valores nulos con la MODA de la columna\n",
    "        else: # Si no es ninguno de los anteriores (en este caso, viendo la tabla anterior, si es un int):\n",
    "            df[col] = df[col].fillna(df[col].median()) # Sustituimos los valores nulos con la MEDIANA de la columna\n",
    "    return df\n",
    "\n",
    "df = impute_missing_values(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No         0\n",
      "year       0\n",
      "month      0\n",
      "day        0\n",
      "hour       0\n",
      "PM2.5      0\n",
      "PM10       0\n",
      "SO2        0\n",
      "NO2        0\n",
      "CO         0\n",
      "O3         0\n",
      "TEMP       0\n",
      "PRES       0\n",
      "DEWP       0\n",
      "RAIN       0\n",
      "wd         0\n",
      "WSPM       0\n",
      "station    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#vemos que ya no hay valores nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, hemos arreglado la base de datos. Además, al haber tantos datos (muestra de 420k datos en total) y pocos datos nulos (4,92% en el peor de los casos) no es especialmente descabellado proponer como método de sustitución de valores nulos la media, moda y mediana según corresponda. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis estadístico de los datos (Explayarse todo lo que uno quiera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora te toca, ¿eres capaz de leer todos los `csv`, concatenarlos y construir un `pd.DataFrame` en una sola línea de código?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df = pd.concat([pd.read_csv(elem) for elem in os.listdir()]).reset_index(drop=True)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
